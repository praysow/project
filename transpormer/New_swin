import torch
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torchvision.models.detection as detection
from torch.utils.data import DataLoader
from torchvision.datasets import VOCDetection
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image, ImageDraw

# Load and prepare the VOC dataset
transform = transforms.Compose([
    transforms.ToTensor()
])

train_dataset = VOCDetection(root='./data', year='2012', image_set='train', download=True, transform=transform)
test_dataset = VOCDetection(root='./data', year='2012', image_set='val', download=True, transform=transform)

train_loader = DataLoader(dataset=train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))
test_loader = DataLoader(dataset=test_dataset, batch_size=2, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))

# Load a pre-trained Faster R-CNN model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = detection.fasterrcnn_resnet50_fpn(pretrained=True)
model.to(device)

# Define the optimizer
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Function to train the model
def train_model(model, train_loader):
    model.train()
    for images, targets in train_loader:
        images = list(image.to(device) for image in images)
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
        
        optimizer.zero_grad()
        loss_dict = model(images, targets)
        losses = sum(loss for loss in loss_dict.values())
        losses.backward()
        optimizer.step()
    print(f'Training Loss: {losses.item()}')

# Function to test the model
def test_model(model, test_loader):
    model.eval()
    with torch.no_grad():
        for images, targets in test_loader:
            images = list(image.to(device) for image in images)
            predictions = model(images)
            for i, image in enumerate(images):
                img = transforms.ToPILImage()(image.cpu())
                draw = ImageDraw.Draw(img)
                for box, label, score in zip(predictions[i]['boxes'], predictions[i]['labels'], predictions[i]['scores']):
                    if score > 0.5:
                        draw.rectangle(((box[0], box[1]), (box[2], box[3])), outline="red", width=3)
                        draw.text((box[0], box[1]), f"{label}: {score:.2f}", fill="red")
                img.show()

# Training and testing
num_epochs = 1
for epoch in range(num_epochs):
    print(f'Epoch {epoch+1}/{num_epochs}')
    train_model(model, train_loader)
    test_model(model, test_loader)

# Testing on a specific image
image_path = '/mnt/data/image.png'
image = Image.open(image_path).convert("RGB")
image_tensor = transform(image).unsqueeze(0).to(device)

model.eval()
with torch.no_grad():
    prediction = model(image_tensor)[0]

draw = ImageDraw.Draw(image)
for box, label, score in zip(prediction['boxes'], prediction['labels'], prediction['scores']):
    if score > 0.5:
        draw.rectangle(((box[0], box[1]), (box[2], box[3])), outline="red", width=3)
        draw.text((box[0], box[1]), f"{label}: {score:.2f}", fill="red")

image.show()
